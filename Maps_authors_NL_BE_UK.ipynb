{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNitTM0u4eEWJSNBFKHNEKZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lorenafc/Capita_Selecta_RHI50403/blob/main/Maps_authors_NL_BE_UK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#install libraries\n",
        "!pip install cartopy -q\n",
        "!pip install contextily -q\n",
        "!pip install pyproj -q\n",
        "!pip install matplotlib-scalebar -q"
      ],
      "metadata": {
        "id": "clWD_FY6Vw_v"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import contextily as cx\n",
        "import os\n",
        "import imageio\n",
        "import random\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "from pyproj import Geod\n",
        "from moviepy.editor import ImageSequenceClip\n",
        "from shapely.geometry import Point, LineString\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib_scalebar.scalebar import ScaleBar\n",
        "import matplotlib.patches as mpatches\n"
      ],
      "metadata": {
        "id": "-pelWQIr9z3U"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import and mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7DTKQfyAEOZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe5df6f8-f973-410d-f25d-d0fea95bbdbb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = 'additional_authors_complete_geocoded_GoogleAPI_drive.xlsx'\n",
        "authors_small_cities = pd.read_excel(file_name, engine='openpyxl')"
      ],
      "metadata": {
        "id": "PZpezjrVi3Ef"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name_ns = 'belgiumnetherlandsuk.xlsx'\n",
        "north_sea = pd.read_excel(file_name_ns, engine='openpyxl')\n",
        "\n"
      ],
      "metadata": {
        "id": "y998NiGa9X8R"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the shapefiles\n",
        "netherlands = gpd.read_file('nl.shp').to_crs(epsg=3857)\n",
        "belgium = gpd.read_file('uk.shp').to_crs(epsg=3857)\n",
        "uk = gpd.read_file('be.shp').to_crs(epsg=3857)"
      ],
      "metadata": {
        "id": "0gkIbEVbgSW8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the shapefiles into a single GeoDataFrame\n",
        "combined_shapefile = pd.concat([netherlands, belgium, uk])"
      ],
      "metadata": {
        "id": "8uBtL2nqh_EM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors_small_cities = authors_small_cities.rename(columns={'bitrhyear': 'birthyear'})"
      ],
      "metadata": {
        "id": "80G7d4eer_pb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create GeoSeries for birth, death, and active points\n",
        "birth_points = gpd.GeoSeries([Point(xy) if pd.notnull(xy[0]) and pd.notnull(xy[1]) else None\n",
        "                              for xy in zip(authors_small_cities['longitude_born'], authors_small_cities['latitude_born'])], crs=\"EPSG:4326\")\n",
        "death_points = gpd.GeoSeries([Point(xy) if pd.notnull(xy[0]) and pd.notnull(xy[1]) else None\n",
        "                              for xy in zip(authors_small_cities['longitude_death'], authors_small_cities['latitude_death'])], crs=\"EPSG:4326\")\n",
        "active_points = gpd.GeoSeries([Point(xy) if pd.notnull(xy[0]) and pd.notnull(xy[1]) else None\n",
        "                               for xy in zip(authors_small_cities['longitude_active'], authors_small_cities['latitude_active'])], crs=\"EPSG:4326\")\n",
        "\n",
        "# Combine birth, death, and active points into a single GeoSeries, prioritizing death points first, then active points, and finally birth points\n",
        "combined_points = death_points.fillna(active_points).fillna(birth_points)\n",
        "\n",
        "# Now create a GeoDataFrame using the combined geometry column\n",
        "authors_small_cities_combined = gpd.GeoDataFrame(authors_small_cities, geometry=combined_points)\n",
        "authors_small_cities_combined = authors_small_cities_combined[authors_small_cities_combined.geometry.notnull()]\n",
        "\n",
        "# Adjust the years: prioritize death year, if missing, use birth year + 60\n",
        "# Convert 'birthyear' to numeric, coerce errors to NaN\n",
        "authors_small_cities_combined['birthyear'] = pd.to_numeric(authors_small_cities_combined['birthyear'], errors='coerce')\n",
        "authors_small_cities_combined['effective_year'] = authors_small_cities_combined['deathyear'].fillna(authors_small_cities_combined['birthyear'] + 60)\n",
        "\n",
        "# Set the CRS for the new GeoDataFrame\n",
        "authors_small_cities_combined = authors_small_cities_combined.set_crs(\"EPSG:4326\").to_crs(epsg=3857)\n",
        "\n",
        "# Filter the DataFrame from 800 to 1800\n",
        "authors_small_cities_combined = authors_small_cities_combined[\n",
        "    (authors_small_cities_combined['effective_year'] >= 800) & (authors_small_cities_combined['effective_year'] <= 1800)\n",
        "].copy()"
      ],
      "metadata": {
        "id": "6IxRBOY9nMvP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a60e7f07-e510-4eb0-b4e7-aaf19e5c1d84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/geopandas/geodataframe.py:1538: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/geopandas/geodataframe.py:1538: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spatial join to filter points within the combined shapefile\n",
        "authors_within_boundaries = gpd.sjoin(authors_small_cities_combined, combined_shapefile, op='within')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQuGi7msil8O",
        "outputId": "7cda9c72-7af4-4a7d-c9dc-9ee7a2f8c9f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3473: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
            "  if (await self.run_code(code, result,  async_=asy)):\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to GeoDataFrame\n",
        "northsea_gdf = gpd.GeoDataFrame(\n",
        "    north_sea, geometry=gpd.points_from_xy(north_sea.longitude, north_sea.latitude), crs=\"EPSG:4326\"\n",
        ")\n",
        "\n",
        "# Convert to Web Mercator projection\n",
        "northsea_gdf = northsea_gdf.to_crs(epsg=3857)"
      ],
      "metadata": {
        "id": "-vxPg95gnaF6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# source: chatGPT and Lucas Koren\n",
        "\n",
        "# Define the start and end years\n",
        "startyear = 800\n",
        "endyear = 1800\n",
        "step = 1\n",
        "\n",
        "output_images_dir = \"/content/drive/My Drive/capita_selecta/nlbeuk/\"\n",
        "os.makedirs(output_images_dir, exist_ok=True)\n",
        "\n",
        "# The Netherland boundaries in Web Mercator projection\n",
        "world_bounds = [0, 6000000, 837000, 7500000]\n",
        "\n",
        "# Invisible points to ensure full basemap is displayed\n",
        "invisible_points = gpd.GeoDataFrame({\n",
        "    'geometry': [\n",
        "        Point(-20037508.34, -20037508.34),  # Bottom left\n",
        "        Point(20037508.34, -20037508.34),   # Bottom right\n",
        "        Point(-20037508.34, 20037508.34),   # Top left\n",
        "        Point(20037508.34, 20037508.34)     # Top right\n",
        "    ],\n",
        "    'point_count': [0, 0, 0, 0]\n",
        "}, crs=\"EPSG:3857\")\n",
        "\n",
        "# Define a custom color map with inverted greyscale\n",
        "cmap = mcolors.ListedColormap(['#000000', '#303030', '#4D4D4D', '#696969', '#8C8C8C', '#B0B0B0'])\n",
        "bounds = [1, 3, 6, 9, 12, 15]\n",
        "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "# Function to determine opacity\n",
        "def get_opacity(count):\n",
        "    if count >= 15:\n",
        "        return 0.4\n",
        "    elif count >= 9:\n",
        "        return 0.6\n",
        "    else:\n",
        "        return 1.0\n",
        "\n",
        "# Function to plot maps for each year\n",
        "def plot_maps_per_year(startyear, endyear, combined_authors, northsea_gdf):\n",
        "    for year in range(startyear, endyear + 1):\n",
        "        #Filter the GeoDataFrame for authors active in the timestep for 10 years prior to their death\n",
        "        authors_active_timestep = combined_authors[\n",
        "            (combined_authors['effective_year'] > year) &\n",
        "            (combined_authors['effective_year'] <= year+10)\n",
        "        ]\n",
        "\n",
        "\n",
        "        # Filter the northsea GeoDataFrame for points in the current year\n",
        "        northsea_active_timestep = northsea_gdf[northsea_gdf['finalcedate'] == year]\n",
        "\n",
        "        # Combine both GeoDataFrames\n",
        "        combined_active_timestep = pd.concat([authors_active_timestep, northsea_active_timestep])\n",
        "\n",
        "\n",
        "\n",
        "        # Check if there are any valid records for the current year\n",
        "        if not combined_active_timestep.empty:\n",
        "            # Create a point_count column\n",
        "            combined_active_timestep['point_count'] = 1\n",
        "\n",
        "            # Group by unique points and get the count for each group and turn into GeoDataFrame  # source: https://sparkbyexamples.com/pandas/pandas-groupby-sum-examples/\n",
        "            unique_points_gdf = combined_active_timestep.groupby('geometry').agg({'point_count': 'sum'}).reset_index()\n",
        "\n",
        "            # Ensure the CRS is set to EPSG:3857 for latitude and longitude\n",
        "            unique_points_gdf = gpd.GeoDataFrame(unique_points_gdf, geometry='geometry', crs='EPSG:3857')\n",
        "\n",
        "            # Add invisible points to ensure full basemap is displayed\n",
        "            unique_points_gdf = pd.concat([unique_points_gdf, invisible_points], ignore_index=True)\n",
        "\n",
        "            # Add opacity column based on the point_count\n",
        "            unique_points_gdf['opacity'] = unique_points_gdf['point_count'].apply(get_opacity)\n",
        "\n",
        "\n",
        "            # Plotting\n",
        "            fig, ax = plt.subplots(figsize=(19, 10))\n",
        "\n",
        "            # Plotting the points\n",
        "            unique_points_gdf.plot(\n",
        "                ax=ax,\n",
        "                column='point_count',\n",
        "                cmap=cmap,\n",
        "                norm=norm,\n",
        "                markersize=unique_points_gdf['point_count']*10,\n",
        "                alpha=unique_points_gdf['opacity'],\n",
        "                edgecolor='black'\n",
        "            )\n",
        "\n",
        "            # Add basemap with fixed zoom level\n",
        "            cx.add_basemap(ax, attribution=False, zoom=3, crs=unique_points_gdf.crs.to_string(), source=cx.providers.CartoDB.VoyagerNoLabels)\n",
        "            # Setting the bounds\n",
        "            ax.set_xlim(world_bounds[0], world_bounds[2])\n",
        "            ax.set_ylim(world_bounds[1], world_bounds[3])\n",
        "\n",
        "            # Set title and axis labels\n",
        "            ax.set_title(f\"Authors' Hotspots - North Sea area (The Netherlands, Belgium and UK) in {year}\")\n",
        "            ax.set_xlabel('Longitude')\n",
        "            ax.set_ylabel('Latitude')\n",
        "\n",
        "            ax.set_xticks([-1669792, 0, 1113194])\n",
        "            ax.set_xticklabels(['', '0°', ''])\n",
        "\n",
        "            ax.set_yticks([6106854, 7361866, 8399737.88])\n",
        "            ax.set_yticklabels(['', '55° N', ''])\n",
        "\n",
        "            # Adjust position of tick labels\n",
        "            ax.tick_params(axis='x', pad=-15, labelsize=8)\n",
        "            ax.tick_params(axis='y', pad=-30, labelsize=8)\n",
        "\n",
        "            # Adicione uma anotação\n",
        "            ax.annotate(\"Projected Coordinate System:\\n WGS 84 / Pseudo-Mercator\", xy=(0.87,0.04), ha= \"center\", va=\"center\", fontsize=8, xycoords= ax.transAxes)\n",
        "\n",
        "\n",
        "\n",
        "            legend_handles = [\n",
        "                mpatches.Patch(color=\"#000000\", label=\"1-2 authors\"),\n",
        "                mpatches.Patch(color=\"#303030\", label=\"3-5 authors\"),\n",
        "                mpatches.Patch(color=\"#4D4D4D\", label=\"6-8 authors\"),\n",
        "                mpatches.Patch(color=\"#696969\", label=\"9-11 authors\"),\n",
        "                mpatches.Patch(color=\"#8C8C8C\", label=\"12-14 authors\"),\n",
        "                mpatches.Patch(color=\"#B0B0B0\", label=\"15+ authors\")\n",
        "            ]\n",
        "\n",
        "\n",
        "            # Add the legend to the plot\n",
        "            ax.legend(handles=legend_handles, loc='lower left')\n",
        "\n",
        "            x, y, arrow_length = 0.95, 0.95, 0.08\n",
        "            ax.annotate('N', xy=(x, y), xytext=(x, y-arrow_length),\n",
        "                        arrowprops=dict(facecolor='black', width=5, headwidth=15),\n",
        "                        ha='center', va='center', fontsize=20,\n",
        "                        xycoords=ax.transAxes)\n",
        "\n",
        "            # Saving the plot as an image\n",
        "            output_image_path = os.path.join(output_images_dir, f'active_north_sea_{year}.png')\n",
        "            plt.savefig(output_image_path)\n",
        "            plt.close(fig)\n",
        "            # plt.show()\n",
        "\n",
        "# Plot maps per year\n",
        "plot_maps_per_year(startyear, endyear, authors_within_boundaries, northsea_gdf)\n"
      ],
      "metadata": {
        "id": "szM1bkgcMrVd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KbhH3F_cixhx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gif and Video - NL X BE X UK"
      ],
      "metadata": {
        "id": "Mj-Q-RQFChqC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Create the gifs and video\n",
        "#source: https://stackoverflow.com/questions/753190/programmatically-generate-video-or-animated-gif-in-python and chat gpt\n",
        "\n",
        "# Function to extract numerical values from filenames\n",
        "def extract_number(file_name):\n",
        "    match = re.search(r'(\\d+)', file_name)\n",
        "    return int(match.group(0)) if match else -1\n",
        "\n",
        "# Path to the directory containing the images\n",
        "image_dir = \"/content/drive/My Drive/capita_selecta/nlbeuk/\" #update your path\n",
        "\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(image_dir):\n",
        "    print(f\"The directory {image_dir} does not exist.\")\n",
        "else:\n",
        "    print(f\"Directory {image_dir} exists. Proceeding with file processing.\")\n",
        "\n",
        "    # List all the image files in the directory\n",
        "    image_files = sorted(\n",
        "        [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.png')],\n",
        "        key=lambda x: extract_number(os.path.basename(x))\n",
        "    )\n",
        "\n",
        "    # Ensure the list is not empty\n",
        "    if not image_files:\n",
        "        print(\"No images found in the specified directory.\")\n",
        "    else:\n",
        "        # Create a GIF (the gif works with 500 images but not with all of them on colab. I used VS code to make the gif with all the images from 800 to 1800)\n",
        "        # gif_output_path = os.path.join(image_dir, 'authors_active_europe.gif')\n",
        "        # images = [imageio.imread(file) for file in image_files]\n",
        "        # imageio.mimsave(gif_output_path, images, fps=30, loop=0)  # Adjust fps as needed\n",
        "        # print(f\"GIF saved at {gif_output_path}\")\n",
        "\n",
        "        # Create a video\n",
        "        video_output_path = os.path.join(image_dir, 'video_authors_active_NL_BE_UK_googleapi.mp4')\n",
        "        clip = ImageSequenceClip(image_files, fps=30)  # Adjust fps as needed\n",
        "        clip.write_videofile(video_output_path, codec='libx264')\n",
        "        print(f\"Video saved at {video_output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e0f3ef0-a28b-4e5f-8ae0-a1de5e750a6e",
        "id": "neKJlbW-BfkQ"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory /content/drive/My Drive/capita_selecta/nlbeuk_19/ exists. Proceeding with file processing.\n",
            "Moviepy - Building video /content/drive/My Drive/capita_selecta/nlbeuk_19/video_authors_active_NL_BE_UK_googleapi.mp4.\n",
            "Moviepy - Writing video /content/drive/My Drive/capita_selecta/nlbeuk_19/video_authors_active_NL_BE_UK_googleapi.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready /content/drive/My Drive/capita_selecta/nlbeuk_19/video_authors_active_NL_BE_UK_googleapi.mp4\n",
            "Video saved at /content/drive/My Drive/capita_selecta/nlbeuk_19/video_authors_active_NL_BE_UK_googleapi.mp4\n"
          ]
        }
      ]
    }
  ]
}